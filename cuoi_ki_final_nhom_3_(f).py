# -*- coding: utf-8 -*-
"""cuoi_ki_final_nhom_3_(F).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15FCvlJB8epCaUdscteHxfexBed88qb8A

#Install / Import library
"""

!pip install pandas
!pip install numpy
!pip install sklearn
!pip install matplotlib

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm
sns.set()
from sklearn.neighbors import NearestNeighbors
from sklearn.metrics import confusion_matrix
from sklearn.preprocessing import LabelEncoder ,OneHotEncoder
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
from sklearn.model_selection import train_test_split

"""# Data Connection & Description (Kết nối & Mô tả dữ liệu)"""

from google.colab import files
upload= files.upload()

data= pd.read_csv('shopping_trends_updated.csv')

data.head()

"""# Describe data"""

data.info()

data.shape

data.dtypes

data.isnull().sum()

data.duplicated().sum()

data.columns

data.describe()

"""Column Types

Numerical - Age, Purchase Amount (USD), Previous Purchases, Promo Code Used, Payment Method, Frequency of Purchases

Categorical - Gender, Item Purchased,Category, Location, Size, Color,Season,Subscription Status,Shipping Type,

null=non

Mixed - none

# EDA & Preprocessing (Phân tích dữ liệu thăm dò & Tiền xử lý dữ liệu)
"""

data.rename(columns={'Item Purchased':'Item_Purchased','Purchase Amount (USD)':'Purchase_Amount_USD','Review Rating':'Review_Rating','Subscription Status':'Subscription_Status','Shipping Type':'Shipping_Type','Discount Applied':'Discount_Applied','Promo Code Used':'Promo_Code_Used','Previous Purchases':'Previous_Purchases','Payment Method':'Payment_Method','Frequency of Purchases':'Frequency_of_Purchases'},inplace=True)

data.head()

data.info()

#Trực quan tất cả các attribute để tìm outliers
numeric_cols= data.select_dtypes(include=[np.number]).columns
for column in numeric_cols :
    plt.figure(figsize=(10,7))
    plt.hist(data[column], edgecolor ='k',alpha=0.7)
    plt.title(f'distribution of {column}')
    plt.xlabel(column)
    plt.ylabel('Frenquency')
    plt.grid(True)
    plt.show()
  # dữ liệu không có outliers

"""# Phân tích đơn biến trên cột số"""

data['Age'].describe()

data['Age']

sns.displot(data=data,x='Age',kind='hist',bins=20)

plt.figure(figsize=(8, 6))
sns.histplot(data=data, x='Age', kde=True)
plt.title('Age Distribution')
plt.show()

data['Age'].skew()

plt.figure(figsize=(10,7))
data['Age'].plot(kind='box')
# độ tuổi trung bình khoảng 44 tuổi

"""Kết luận tuổi
1. Tuổi gần như có phân bố chuẩn (phân bố đối xứng)
2. Không có outliers
"""

data['Purchase_Amount_USD'].describe()

sns.displot(data=data,x='Purchase_Amount_USD',kind='hist',bins=20)

plt.figure(figsize=(8, 6))
sns.histplot(data=data, x='Purchase_Amount_USD', kde=True)
plt.title('Purchase Amount (USD)')
plt.show()

data['Purchase_Amount_USD'].skew()
# dữ liệu có phân bố chuẩn

plt.figure(figsize=(10,7))
data['Purchase_Amount_USD'].plot(kind='box')

data['Review_Rating'].describe()

sns.displot(data=data,x='Review_Rating',kind='hist',bins=20)

plt.figure(figsize=(8, 6))
sns.histplot(data=data, x='Review_Rating', kde=True)
plt.title('Review Rating')
plt.show()

data['Review_Rating'].skew()

data['Review_Rating'].plot(kind='box')

data['Previous_Purchases'].describe

plt.figure(figsize=(8, 6))
sns.histplot(data=data, x='Previous_Purchases', kde=True)
plt.title('Previous Purchases')
plt.show()

data['Previous_Purchases'].skew()

data['Previous_Purchases'].plot(kind='box')

"""phân bố chuẩn (phân bố đối xứng)
dữ liệu các cột Numerical
1. đã chuẩn hoá
2.phân bố chuẩn (phân bố đối xứng)

## Phân tích đơn biến trên các cột phân loại(categorical )
"""

sns.countplot(x='Subscription_Status',data=data)

sns.countplot(x='Gender',data=data)

Gender_count = data['Gender'].value_counts()
print('number of male',Gender_count['Male'])
print('number of Female',Gender_count['Female'])

# Tính tổng số lượng đằng kí hay không đăng kí mua hàng theo theo nam / nữ
Gender_churn_crosstab= pd.crosstab(data['Subscription_Status'],data['Gender'])
total_count= Gender_churn_crosstab.sum(axis=0)
ax=Gender_churn_crosstab.plot(kind='bar')
plt.xlabel('Subscription Status')
plt.ylabel('Counts')
plt.legend(title='Gender')
plt.title('Gender churn rate')
plt.show()
# lượng không đăng kí rất nhiều và nhóm nữ không có đăng kí dịch vụ mua hàng

plt.figure(figsize=(10,7))
sns.boxplot(data=data,x='Subscription_Status',y='Age')
# dựa vào biểu đò ta có thể thấy được  độ tuổi trung bình của những người đăng kí là 45 so với 44 của những người không đăng kí dịch vụ mua hàng
# nhưng nhìn tổng thể thì khách hàng có hoặc không đăng kí dịch vụ mua hàng thì họ đều trong khoảng độ tuổi từ 30 đến 60

plt.figure(figsize=(10,7))
counts=data['Gender'].value_counts()
plt.pie(counts,labels=counts.index, autopct='%1.1f%%')
plt.title('Gender')

data['Category'].value_counts()

data['Category'].value_counts().plot(kind='bar')
plt.show()

plt.figure(figsize=(10,7))
Cate_counts=data['Category'].value_counts()
plt.pie(Cate_counts,labels=Cate_counts.index, autopct='%1.1f%%')
plt.title('Category')

plt.figure(figsize=(10,7))
data['Item_Purchased'].value_counts().plot(kind='bar')
plt.title('Items purchased')
plt.ylabel('no. of occurrences',fontsize=10)
plt.xlabel('item purchased',fontsize=10)
plt.show()

data['Item_Purchased'].mode()[0]
# áo cánh (Blouse) sản phẩm mua nhiều nhất

plt.figure(figsize=(15,5))
sns.lineplot(data=data,y=data['Previous_Purchases'].value_counts(),x='Item_Purchased',ci=False)
plt.xticks(rotation=90)
plt.show();

# trending items between male and females
plt.figure(figsize=(15,5))
sns.lineplot(data=data,y='Previous_Purchases',x='Item_Purchased',hue='Gender',ci=False)
plt.xticks(rotation=90)
plt.show();

data['Location'].value_counts()

plt.figure(figsize = (10, 7))
data['Location'].value_counts().plot(kind='bar')
plt.show()

data["Size"].value_counts().plot(kind='bar')
plt.show()

data["Season"].value_counts()

plt.figure(figsize = (10, 7))
data['Season'].value_counts().plot(kind='bar')
plt.show()

data['Payment_Method'].value_counts()

plt.figure(figsize = (10, 7))
data['Payment_Method'].value_counts().plot(kind='bar')
plt.show()

data["Shipping_Type"].value_counts()

plt.figure(figsize = (10, 7))
data['Shipping_Type'].value_counts().plot(kind='bar')
plt.show()

data["Frequency_of_Purchases"].value_counts()

data["Frequency_of_Purchases"].value_counts().plot(kind="pie",autopct='%0.1f%%')
plt.show()

data.groupby('Category')['Purchase_Amount_USD'].sum()
# danh thu mỗi sản phẩm . quần áo (Clothing) có doanh thu cao nhất

data.groupby('Gender')['Review_Rating'].mean()
#Đánh giá trung bình của khách hàng nam và khách hàng nữ  gần như bằng nhau

data['Payment_Method'].mode()[0]
# PayPal là hình thưc thanh toán được dùng nhiều nhất

data[data['Subscription_Status'] == 'Yes'].shape[0]
#lượng khách đăng kí dịch vụ mua hàng

avg_purchase_subscription_yes = data[data['Subscription_Status'] == 'Yes']['Purchase_Amount_USD'].mean()
avg_purchase_subscription_no = data[data['Subscription_Status'] == 'No']['Purchase_Amount_USD'].mean()
print("Average Purchase Amount for Subscription 'Yes':", avg_purchase_subscription_yes)
print("Average Purchase Amount for Subscription 'No':", avg_purchase_subscription_no)
#số tiền trung bình khách hàng đăng kí mua và không đăng kí mua gần như bằng nhau nhưng ở không đăng kí lại nhiều hơn một chút

data['Season'].mode()[0]
# Mùa xuân được nhiều người mua hàng nhất

data.groupby('Gender')['Purchase_Amount_USD'].sum()
# nhóm đàn ông mua hàng nhiều hơn nữ gần gấp đôi

data[data['Promo_Code_Used'] == 'Yes'].shape[0]

data[data['Promo_Code_Used'] == 'No'].shape[0]
#khách hàng  không sử dụng dịch vụ khuyến mãi cao hơn với người dùng dịch vụ

data[(data['Gender'] == 'Female') & (data['Review_Rating'] < 3)]['Category'].mode()[0]

data[(data['Gender'] == 'Male') & (data['Review_Rating'] < 3)]['Category'].mode()[0]
# danh muc 'Clothing' được đánh giá dưới 3 nhiều nhất của cả nam và nữ đều như nhau

data.groupby('Location')['Purchase_Amount_USD'].sum()
# doanh thu theo khu vực. tất cả khu vực đều có doanh thu khá cao và đồng đều

"""# Feature Engineering (dự báo tình trạng đăng kí mua hàng)


"""

f = ['Age', 'Gender', 'Item_Purchased', 'Category',
       'Purchase_Amount_USD', 'Location', 'Size', 'Color', 'Season',
       'Review_Rating', 'Subscription_Status', 'Shipping_Type',
       'Discount_Applied', 'Promo_Code_Used', 'Previous_Purchases',
       'Payment_Method', 'Frequency_of_Purchases']

#Hiển thị sơ đồ đường giữa ID khách hàng và tất cả các cột khác trong tập dữ liệu
pno = 1
plt.figure(figsize=(20,30))
for i in f:
    plt.subplot(6,3,pno)
    sns.lineplot(data=data,x=i,y='Customer ID',ci=False)
    pno += 1

data.head()

#thực hiện mã hóa biến phân loại (categorical variable) "Gender" thành các biến giả (dummy variables) trong tập dữ liệu data.
data1=data
data1=pd.get_dummies(data1,columns=['Gender'])
data1.head()

# Vòng lặp để chuyển đổi tất cả các giá trị không phải số thành giá trị số ngoại trừ cột mục tiêu
label_encode= LabelEncoder()
col_list = []
for col in data1.columns:
    if ((data1[col].dtype == 'object') & (col != 'Subscription_Status') ):
        col_list.append(col)

for i in col_list:
    data1[i]=label_encode.fit_transform(data1[i])

# Chuyển đổi cột mục tiêu thành giá trị số, tức là Có = 1 và Không = 0
data1['Subscription_Status'] = np.where(data1['Subscription_Status']=='Yes',1,0)

data1.head()

data1.drop(columns='Customer ID',inplace=True)

# Trực quan dữ liệu bằng biểu đồ scatterplot để mô tả biến mục tiêu với 2 biến phụ thuộc
plt.figure(figsize=(10,7))
sns.scatterplot(x=data1['Age'],y=data1['Purchase_Amount_USD'],hue =data1['Subscription_Status'])

plt.figure(figsize=(10,7))
sns.scatterplot(x=data1['Location'],y=data1['Previous_Purchases'],hue =data1['Subscription_Status'])

plt.figure(figsize=(10,7))
sns.scatterplot(x=data1['Item_Purchased'],y=data1['Payment_Method'],hue =data1['Subscription_Status'])

# Độ tương quan giữa các biến
plt.figure(figsize=(10,7))
sns.heatmap(data1.corr(),annot=True ,cmap='viridis')

"""# Split dataset into training / testing sets & Normalize (if needed)"""

y= data1['Subscription_Status']
feature= data1.columns.difference(['Subscription_Status'])
print(f"feature name :{list(feature)}")
X=data1[feature]

X

X.head()

y.head()

print('X',X.size)
print('y',y.size)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaler.fit(X,y)

print ("X_train", X_train.size)
print ("X_test", X_test.size)

print ("y_train", y_train.size)
print ("y_test", y_test.size)

"""# Training"""

# training model Logistic Regression
from sklearn.linear_model import LogisticRegression

logis_model = LogisticRegression(solver='newton-cg', max_iter=500)
logis_model.fit(X_train, y_train)

# tìm param n_neighbors (hệ số k)
from sklearn import neighbors
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV
params_Knn = {'n_neighbors':list(np.arange(1,30,1))}
clK = KNeighborsClassifier()
model = GridSearchCV(clK, params_Knn, cv = 10)
model.fit(X_train, y_train)
model.best_params_

# training model KNN
from sklearn import neighbors
#  truyền param n_neighbors (hệ số k)
knn_model = neighbors.KNeighborsClassifier(n_neighbors=model.best_params_['n_neighbors'])
knn_model.fit(X_train, y_train)

# training model naive bayes
from sklearn.naive_bayes import GaussianNB

nb_model = GaussianNB()
nb_model.fit(X_train, y_train)

# training model SVM
from sklearn.svm import SVC
svc_model=SVC(probability=True)
svc_model.fit(X_train,y_train)

# tìm param cho Random forest
from sklearn.ensemble import RandomForestClassifier
param_grid = {
    'n_estimators': [50, 100, 150],
    'max_depth': [None, 10, 30, 50],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}
rf_classifier = RandomForestClassifier(random_state=42)
grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)
grid_search.fit(X_train, y_train)
best_params = grid_search.best_params_
print(best_params)

# sets of hyperparameters
from sklearn.metrics import accuracy_score
params_rd1 = {'criterion': 'gini', 'max_depth': 10}
params_rd2 = {'criterion': 'entropy',  'max_depth': 10}
model_rd1 = RandomForestClassifier(**params_rd1)
model_rd2 = RandomForestClassifier(**params_rd2)

model_rd1.fit(X_train, y_train)
model_rd2.fit(X_train, y_train)

preds_rd1 = model_rd1.predict(X_test)
preds_rd2 = model_rd2.predict(X_test)

print(f'Accuracy on Model 1: {round(accuracy_score(y_test, preds_rd1), 3)}')
print(f'Accuracy on Model 2: {round(accuracy_score(y_test, preds_rd2), 3)}')

# training model Random Forest
from sklearn.ensemble import RandomForestClassifier
forest_model = RandomForestClassifier(n_estimators=100,criterion='entropy',max_depth=10,min_samples_split=2,min_samples_leaf=2, random_state=42)
forest_model.fit(X_train, y_train)

# sets of hyperparameters Decision Tree
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV

dtc = DecisionTreeClassifier()
depth = np.arange(1, 30)
leaves = [1, 2, 4, 5, 10, 20, 30, 40, 80, 100]

param_grid_tree = [{'max_depth': depth, 'min_samples_leaf': leaves}]

grid_search_tree = GridSearchCV(estimator=dtc, param_grid=param_grid_tree, scoring='accuracy', cv=10)
grid_search_t = grid_search_tree.fit(X_train, y_train)

best_params_tree = grid_search_t.best_params_
print(best_params_tree)

# sets of hyperparameters
from sklearn.metrics import accuracy_score
params_tr1 = {'criterion': 'gini', 'splitter': 'best', 'max_depth': 1}
params_tr2 = {'criterion': 'entropy', 'splitter': 'random', 'max_depth': 1}
params_tr3 = {'criterion': 'gini', 'splitter': 'random', 'max_depth': 1}
params_tr4 = {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 1}
model_tr1 = DecisionTreeClassifier(**params_tr1)
model_tr2 = DecisionTreeClassifier(**params_tr2)
model_tr3 = DecisionTreeClassifier(**params_tr3)
model_tr4 = DecisionTreeClassifier(**params_tr4)
model_tr1.fit(X_train, y_train)
model_tr2.fit(X_train, y_train)
model_tr3.fit(X_train, y_train)
model_tr4.fit(X_train, y_train)
preds_tr1 = model_tr1.predict(X_test)
preds_tr2 = model_tr2.predict(X_test)
preds_tr3 = model_tr3.predict(X_test)
preds_tr4 = model_tr4.predict(X_test)
print(f'Accuracy on Model 1: {round(accuracy_score(y_test, preds_tr1), 3)}')
print(f'Accuracy on Model 2: {round(accuracy_score(y_test, preds_tr2), 3)}')
print(f'Accuracy on Model 1: {round(accuracy_score(y_test, preds_tr3), 3)}')
print(f'Accuracy on Model 2: {round(accuracy_score(y_test, preds_tr4), 3)}')
#kết quả giống nhau nên có thể để default

# training model Decision Tree
from sklearn.tree import DecisionTreeClassifier
tree_model= DecisionTreeClassifier(criterion='gini',max_depth=1,min_samples_leaf=1, random_state=42)
tree_model.fit(X_train,y_train)

"""# Evaluation(Classification)"""

from sklearn.metrics import fbeta_score,make_scorer
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix,accuracy_score,f1_score,roc_auc_score,roc_curve,classification_report

logis_model_y_pred= logis_model.predict(X_test)
logis_model_y_pred

knn_model_y_pred=knn_model.predict(X_test)
knn_model_y_pred

nb_model_y_pred= nb_model.predict(X_test)
nb_model_y_pred

svc_model_y_pred= svc_model.predict(X_test)
svc_model_y_pred

forest_model_y_pred=forest_model.predict(X_test)
forest_model_y_pred

tree_model_y_pred= tree_model.predict(X_test)
tree_model_y_pred

def evaluation (X_test,clf,y_test):
  y_pred = clf.predict(X_test)
  print('CLASSIFICATION REPORT')
  print(classification_report(y_test,y_pred))
  print('F1_score')
  print(np.round(f1_score(y_test,y_pred)*100,2))
  print('ACCURACY')
  accuracy= accuracy_score(y_test,y_pred)
  print(np.round(accuracy*100,2),'%')
  cm=confusion_matrix(y_test,y_pred)
  print('confusion matrix:\n',cm)
  plt.figure(figsize=(5,6))
  sns.heatmap(cm,annot=True,cmap= 'coolwarm',fmt='d')
  plt.show()

evaluation(X_test,logis_model,y_test)

evaluation(X_test,knn_model,y_test)

evaluation(X_test,nb_model,y_test)

evaluation(X_test,svc_model,y_test)

evaluation(X_test,tree_model,y_test)

evaluation(X_test,forest_model,y_test)

"""# Feature Engineering( tìm phân khúc bằng k-meam)"""

data

"""#Calculate RFM and RFM_Score"""

def Recency	 (Previous_Purchases):
    if Previous_Purchases<=10:
        return 1
    elif Previous_Purchases>10 and Previous_Purchases<=20:
        return 2
    elif Previous_Purchases>20 and Previous_Purchases<=30:
        return 3
    elif Previous_Purchases>30 and Previous_Purchases<=40:
        return 4
    else:
        return 5

data['Recency'] = data['Previous_Purchases'].apply(Recency)

def Frequency (Frequency_of_Purchases):
    if Frequency_of_Purchases=='Weekly':
        return 5
    elif Frequency_of_Purchases=='Fortnightly' or 'Bi-Weekly':
        return 4
    elif Frequency_of_Purchases=='Monthly':
        return 3
    elif Frequency_of_Purchases=='Quarterly' or 'Every 3 Months':
        return 2
    else:
        return 1

data['Frequency'] = data['Frequency_of_Purchases'].apply(Frequency)

data.head()

data.Purchase_Amount_USD.value_counts()

data['Purchase_Amount_USD'].min()

data['Purchase_Amount_USD'].max()

def monetary (Purchase_Amount_USD):
    if Purchase_Amount_USD<=35:
        return 1
    elif Purchase_Amount_USD>35 and Purchase_Amount_USD<=50:
        return 2
    elif Purchase_Amount_USD>50 and Purchase_Amount_USD<=75:
        return 3
    elif Purchase_Amount_USD>75 and Purchase_Amount_USD<=90:
        return 4
    else:
        return 5

data['Monetary'] = data['Purchase_Amount_USD'].apply(monetary)

data.head()

rfm_data= data[['Customer ID','Recency','Frequency','Monetary']]

rfm_data.head()

"""# Training

"""

!pip install kneed

import matplotlib.pyplot as plt
from kneed import KneeLocator
from sklearn.datasets import make_blobs
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from sklearn.preprocessing import StandardScaler

# Calculating RFM score
rfm_data['RFM_Score'] = 0.15*rfm_data['Recency'] + 0.28*rfm_data['Frequency'] + 0.57*rfm_data['Monetary']
rfm_df = rfm_data.round(2)
rfm_df[['Customer ID', 'RFM_Score']].head(7)

rfm_df['RFM_Score'].min()

rfm_df['RFM_Score'].max()

# Rating Customer based upon the RFM score
rfm_df["Customer_segment"] = np.where(rfm_df['RFM_Score'] > 4.5, "Top Customers",
									(np.where(rfm_df['RFM_Score'] > 4, "High value Customer",
										(np.where(rfm_df['RFM_Score'] > 3, "Medium Value Customer",
							np.where(rfm_df['RFM_Score'] > 2, 'Low Value Customers', 'Lost Customers'))))))
rfm_df[['Customer ID', 'RFM_Score', 'Customer_segment']].head(20)

# Visualizing customer segments
plt.pie(rfm_df.Customer_segment.value_counts(),
		labels=rfm_df.Customer_segment.value_counts().index,
		autopct='%.0f%%')
plt.show()

"""đây là cách truyền thống

# cách K-Mean
"""

!pip install kneed

from kneed import KneeLocator
from sklearn.metrics import silhouette_score
from sklearn.cluster import KMeans

data2=data[['Previous_Purchases','Frequency','Purchase_Amount_USD']]
data2.rename(columns={'Purchase_Amount_USD':'monetary','Previous_Purchases':'recency','Frequency':'frequency'},inplace=True)

data2

X = data2.iloc[:].values
#feature scaling
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
data3 = scaler.fit_transform(X)

kmeans_kwargs = {
"init": "random",
"n_init": 10,
"max_iter": 300,
"random_state": 42,
}

# A list holds the SSE values for each k
sse = []
for k in range(1, 11):
 kmeans = KMeans(n_clusters=k, **kmeans_kwargs)
 kmeans.fit(data3)
 sse.append(kmeans.inertia_)

plt.style.use("fivethirtyeight")
plt.plot(range(1, 11), sse)
plt.xticks(range(1, 11))
plt.xlabel("Number of Clusters")
plt.ylabel("SSE")
plt.show()

kl = KneeLocator(range(1,11),sse,curve= 'convex',direction='decreasing')
kl.elbow

silhoutte_coef = []
for k in range(2,11):
  kmeans=KMeans(n_clusters=k,**kmeans_kwargs)
  kmeans.fit(data3)
  score= silhouette_score(data3,kmeans.labels_)
  silhoutte_coef.append(score)

plt.style.use('fivethirtyeight')
plt.plot(range(2,11),silhoutte_coef)
plt.xticks(range(2,11))
plt.xlabel('number of Clusters')
plt.ylabel('Siuloutte of coefficient')
plt.show()

# test t = 4
kmeans = KMeans(n_clusters = 4, init = 'k-means++', random_state = 42)
y_kmeans = kmeans.fit_predict(data3)

plt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], s = 50, c = 'red', label = 'Cluster 1')
plt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], s = 50, c = 'blue', label = 'Cluster 2')
plt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], s = 50, c = 'green', label = 'Cluster 3')
plt.scatter(X[y_kmeans == 3, 0], X[y_kmeans == 3, 1], s = 50, c = 'cyan', label = 'Cluster 4')
plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 100, c = 'yellow', label = 'Centroids')
plt.title('Clusters of customers')
plt.xlabel('recency',fontsize=10)
plt.ylabel('frequency',fontsize=10)
plt.tick_params(labelsize = 8)
plt.legend()
plt.show()

#test k=5
plt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], s = 100, c = 'red', label = 'Cluster 1')
plt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], s = 100, c = 'blue', label = 'Cluster 2')
plt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], s = 100, c = 'green', label = 'Cluster 3')
plt.scatter(X[y_kmeans == 3, 0], X[y_kmeans == 3, 1], s = 100, c = 'cyan', label = 'Cluster 4')
plt.scatter(X[y_kmeans == 4, 0], X[y_kmeans == 4, 1], s = 100, c = 'magenta', label = 'Cluster 5')
plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 300, c = 'yellow', label = 'Centroids')
plt.title('Clusters of customers')
plt.xlabel('recency',fontsize=10)
plt.ylabel('frequency',fontsize=10)
plt.tick_params(labelsize = 8)
plt.legend()
plt.show()

"""chọn k=5"""

data2

sns.pairplot(data2, diag_kind='kde')

from sklearn.cluster import KMeans

#  t = 5
kmeans = KMeans(n_clusters = 5, init = 'k-means++', random_state = 42)
y_kmeans = kmeans.fit_predict(X)
#labels = kmeans.labels_

y_kmeans

data2['Cluster']=y_kmeans

data2

d = {'recency':'Avg_Recency', 'frequency':'AVG_Frequency', 'monetary':'AVG_Monetary'}
df_RFM_mean = data2.groupby('Cluster').agg({'recency':'mean', 'frequency':'mean','monetary': 'mean'}).rename(columns=d)

df_RFM_mean

data2.groupby('Cluster').agg(['max','min'])['recency']

data2.groupby('Cluster').agg(['max','min'])['frequency']

data2.groupby('Cluster').agg(['max','min'])['monetary']

data2['segment'] = data2['Cluster'].replace(to_replace=[0,1,2,3,4], value = ['Lost Value Customer', 'High Customer', 'Top Value Customer', 'Low Value Customer','Medium Customers'])

data2

# Visualizing customer segments
plt.pie(data2.segment.value_counts(),
		labels=data2.segment.value_counts().index,
		autopct='%.2f%%')
plt.tick_params(labelsize = 8)
plt.show()

"""# Tổng hợp đánh giá"""

data

data2['Subscription_Status']=data['Subscription_Status']
data2['Discount_Applied']= data['Discount_Applied']

data2

#lọc Subscription_Status có giá trị Yes nhóm theo clusters
result1=data2[data2['Subscription_Status'] == 'Yes'].groupby('Cluster').agg({
    'Cluster': 'count',
})
result1 = result1.rename(columns={'Cluster': 'counts'})
result1

#lọc Subscription_Status có giá trị No nhóm theo clusters
result2=data2[data2['Subscription_Status'] == 'No'].groupby('Cluster').agg({
    'Cluster': 'count',
})
result2 = result2.rename(columns={'Cluster': 'counts'})
result2

# #lọc Discount_Applied có giá trị No nhóm theo  clusters
result3=data2[data2['Discount_Applied'] == 'No'].groupby('Cluster').agg({
    'Cluster': 'count'
})
result3 = result3.rename(columns={'Cluster': 'counts'})
result3

# #lọc Discount_Applied có giá trị Yes nhóm theo  clusters
result4=data2[data2['Discount_Applied'] == 'Yes'].groupby('Cluster').agg({
    'Cluster': 'count'
})
result4 = result4.rename(columns={'Cluster': 'counts'})
result4

#Có bao nhiêu khách hàng đã mua hàng ở mỗi danh mục?
purchase_count_by_category = data['Category'].value_counts()
print("Purchase Count by Category:")
print(purchase_count_by_category)

common_category_low_rating_male = data[(data['Gender'] == 'Male') & (data['Review_Rating'] < 3)]['Category'].mode()[0]
print("Danh mục phổ biến nhất dành cho khách hàng nam có xếp hạng thấp :", common_category_low_rating_male)

common_category_low_rating_male = data[(data['Gender'] == 'Male') & (data['Review_Rating'] > 3)]['Category'].mode()[0]
print("Danh mục phổ biến nhất dành cho khách hàng nam có xếp hạng cao :", common_category_low_rating_male)

subscription_promo_count = data[(data['Subscription_Status'] == 'Yes') & (data['Promo_Code_Used'] == 'Yes')]['Customer ID'].count()
print("khách hàng có trạng thái đăng ký là 'Có' và đã sử dụng mã khuyến mãi để mua hàng: ", subscription_promo_count)

subscription_promo_count = data[(data['Subscription_Status'] == 'No') & (data['Promo_Code_Used'] == 'No')]['Customer ID'].count()
print("khách hàng có trạng thái đăng ký là 'không' và có sử dụng mã khuyến mãi để mua hàng: ", subscription_promo_count)

"""1. xem xét tình hình hoạt động của doanh nghiệp
từ khám phá ban đầu dữ liệu ta tổng hợp được các thông tin sau :

  - tỉ lệ người đăng kí dịch vụ mua hàng thấp rất chiếm 27% so với 73%  những người không đăng kí mua hàng
  - lượng không đăng kí mua rất nhiều và nhóm nữ không có đăng kí dịch vụ mua hàng
  - khách hàng nam chiếm 68% so với khách hàng nữ
  - khách hàng  không sử dụng dịch vụ khuyến mãi cao hơn với người dùng dịch vụ
  - Danh mục phổ biến nhất dành cho khách hàng nam có xếp hạng thấp : Clothing
  - Danh mục phổ biến nhất dành cho khách hàng nam có xếp hạng cao : Clothing
  - khách hàng có trạng thái đăng ký là 'Có' và đã sử dụng mã khuyến mãi để mua hàng:  1053
  - khách hàng có trạng thái đăng ký là 'không' và có sử dụng mã khuyến mãi để mua hàng:  2223
  - độ tuổi trung bình của những người đăng kí là 45 so với 44 của những người không đăng kí dịch vụ mua hàng

--> từ những tổng ta có những kết luận là :

  -  doanh nghiệp đã không hoạt động tốt trong việc chăm sóc các khách hàng cũ là khách hàng đăng ký dịch vụ mua hàng và các khách hàng mới là các khách hàng không đăng kí dịch vụ
  -  sử dụng các dịch vụ khuyến mãi không hiệu quả. không đúng với các đối tượng cần chăm sóc là các nhóm khách hàng đăng kí dịch vụ và nhóm khách hàng chủ yếu	Medium Value Customer(tiêu dùng trung bình từ 60 USD) và nhóm Top Value (trung bình 80 USD)

--> giải pháp:

   - từ những dữ liệu trên ta có thể đề xuất các biện pháp chăm sóc hiệu quả bằng cách chia 2 loại khuyến mãi : đối với nhóm khách hàng không đăng kí dịch vụ chỉ khuyến mãi các dịch vụ giảm giá thấp từ 5% trở xuống và đối với nhóm đăng kí dịch vụ ta có thể khuyến mãi các dịch vụ giảm giá từ 10% trở đi và các hoạt động giảm giá cao hơn trong các dịp lễ cũng áp dụng cho các
   - khách hàng đăng kí dịch vụ  nhóm Medium Value Custome và Top Value nên ta có thể kinh doanh nhiều các mặt hàng sản phẩm phù hợp  2 nhóm khách hàng mục tiêu nhiều hơn nhằm đa dạng hoá kiểu dáng và mẫu mã kích thích nhu cầu mua sắm đối với nhóm khách hàng này
   - nhóm khách hàng chủ yếu là lớp trung niên từ 44 tuôi nên các mặt hàng thời trang hợp với tuổi tác và khí hậu mối vùng
  
"""